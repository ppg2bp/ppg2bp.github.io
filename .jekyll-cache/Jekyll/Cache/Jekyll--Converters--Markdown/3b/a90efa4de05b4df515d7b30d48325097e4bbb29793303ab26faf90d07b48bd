I"y<h2> Motivation </h2>
<p>: In contrast to the traditional narrative review, we propose to summarize the findings of studies via a systematic review. Due to the large number of studies and the large variation in study datasets, protocols and results, a systematic review with a meta-analysis is warranted to qualify the best design considerations and areas for improvement.</p>

<h2> Protocol and Registration, Information Sources, and Search </h2>
<p>‚Äúphotoplethysmography‚Äù, ‚Äúppg‚Äù, and ‚Äúblood pressure‚Äù were entered into the search tool Publish or Perish which retrieves and analyzes academic citations from external data sources, including Crossref, Google Scholar, Google Scholar Profile, Microsoft Academic, OpenAlex, PubMed, Scopus, Semantic Scholar and Web of Science. The Maximum number of results were specified as 1000 and the articles were specified in the time-frame of 1979-2022.</p>
<h2> Study selection </h2>
<p>The compiled database included studies reporting SBP and/or DBP errors for classification and/or regression metrics. Moreover, missing papers and whitepapers were included on a case-by-case basis. Some studies are published more than once. Duplicate publications were identified and reported only once.
Eligibility criteria: Studies published in the English language that use PPG (both single-site and multi-site approaches) for BP estimation that report mean error (ME) and standard deviation (STD), or mean absolute error in mmHg for Systolic Blood Pressure (SBP) and/or Diastolic Blood Pressure (DBP). No constraint on subject demographics or population statistics. 
Data Collection Process: Independent extraction of n=___ unique articles by a single author using predefined data fields. For studies that had multiple protocols and reported multiple results, the multiple entries were made in the compiled database.</p>
<h2> Data Items </h2>
<p>Information from each included approach (hardware/software, regression/classification), key devices and features (i.e. device=PPG, measurement = whole based features), calibration technique (record level split without personalization, subject level split, personalization, and some details), algorithm (i.e. physiological model using Moens‚Äì Korteweg equation, classical machine learning using decision trees, deep learning using convolutional neural networks), dataset(s), number of subjects, subject characteristics (i.e. ICU patients, healthy males), study characteristics (observational or interventional), evaluation metric (i.e. MAE, ME¬±STD, MSE, % accuracy), and reported numerical results. For studies that performed personalization, additional fields included number of calibrations, number of tests, time between calibration and test, time of test, time of calibration, time of test and errors. For studies that included both MAE and ME¬±STD, the ME¬±STD was recorded. If studies included multiple reported values for the same experimental setup, the smallest error was reported.</p>
<h2> Risk of bias in individual studies </h2>
<p>Because one author summarized all studies, there could have been bias in extracting the results. To alleviate this bias and to reduce error, the studies were summarized twice.</p>
<h2> Summary measures </h2>
<p>Since the Universal Standard uses ME¬±STD and the IEEE standard uses MAE, we choose to alleviate this discrepancy and by assuming gaussian statistics and converting summary measures reported as ME¬±STD (gaussian distribution) to MAE (folded normal distribution). The mean and confidence intervals are reported for each dimension. MAE is readily interpretable, scientifically meaningful and comparable among meta-analyses, and has known sampling distribution.</p>
:ET