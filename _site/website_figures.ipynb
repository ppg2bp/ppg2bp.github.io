{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f084d840-fab3-4f8f-9f45-b5acb8d0d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from scipy import stats\n",
    "\n",
    "from bokeh.plotting import figure, show, curdoc\n",
    "from bokeh.io import output_file\n",
    "from bokeh.layouts import row, column, gridplot\n",
    "from bokeh.models import ColumnDataSource, Legend, BoxAnnotation, HoverTool, Plot, FactorRange, TapTool, OpenURL, Range1d\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ff9ff8-5b3c-4ee5-8f77-d289125f62d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-25 16:30:51--  https://docs.google.com/spreadsheets/d/1O8YItuJ4CtaFFEXbjBcxvhUoM7v9AX1uFDRMhh7iQZM/export?format=xlsx\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.138.102, 142.250.138.101, 142.250.138.113, ...\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.138.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: https://doc-14-5g-sheets.googleusercontent.com/export/mq6he3r7ig44qobar1fsg51390/66shevbaer6bovsdsef3velagk/1674685850000/102025844088317935117/*/1O8YItuJ4CtaFFEXbjBcxvhUoM7v9AX1uFDRMhh7iQZM?format=xlsx [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-01-25 16:30:51--  https://doc-14-5g-sheets.googleusercontent.com/export/mq6he3r7ig44qobar1fsg51390/66shevbaer6bovsdsef3velagk/1674685850000/102025844088317935117/*/1O8YItuJ4CtaFFEXbjBcxvhUoM7v9AX1uFDRMhh7iQZM?format=xlsx\n",
      "Resolving doc-14-5g-sheets.googleusercontent.com (doc-14-5g-sheets.googleusercontent.com)... 142.251.32.193\n",
      "Connecting to doc-14-5g-sheets.googleusercontent.com (doc-14-5g-sheets.googleusercontent.com)|142.251.32.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
      "Saving to: ‘../metadata.xlsx’\n",
      "\n",
      "../metadata.xlsx        [ <=>                ]   1.20M  6.77MB/s    in 0.2s    \n",
      "\n",
      "2023-01-25 16:30:53 (6.77 MB/s) - ‘../metadata.xlsx’ saved [1256320]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://docs.google.com/spreadsheets/d/1O8YItuJ4CtaFFEXbjBcxvhUoM7v9AX1uFDRMhh7iQZM/export?format=xlsx\" -O \"../metadata.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb171cb-fa09-434d-90c2-ff2cc57d489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../metadata.xlsx', sheet_name='WearableBP Paper Metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b492706-ac71-48ee-8703-8dff6f1aa116",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a68f054-dafd-42af-87bc-dd13ceef12c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/matt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from rake_nltk import Rake\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def find_keywords(x, include_columns):\n",
    "    s = ''\n",
    "    for col in include_columns:\n",
    "        if x[col] != x[col]:\n",
    "            pass\n",
    "        else:\n",
    "            s += ' ' + str(x[col])\n",
    "            \n",
    "    rake_nltk_var = Rake()\n",
    "    rake_nltk_var.extract_keywords_from_text(s)\n",
    "    keywords = rake_nltk_var.get_ranked_phrases()\n",
    "    return ' '.join(keywords)\n",
    "\n",
    "include_columns = ['Authors', 'Title', 'Source', 'Exclude Reason', 'Key Devices and Measurements', 'Calibration Technique', 'Algorithm', 'Dataset', 'Training Subject Characteristics', 'Testing Subject Characteristics', 'Study Characteristics','Evaluation Metric', 'Notes', 'Abstract']\n",
    "data['Keywords'] = data.apply(find_keywords, axis=1, args=(include_columns, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06991275-0c79-4ff3-b94a-88a6eb59742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data.copy().dropna(subset='Exclude Reason')\n",
    "len(a[a['Exclude Reason'].str.contains('record split without personalization')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec84faa-ea83-4e03-9261-f09b5729201e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compress_authors(x):\n",
    "    a = x.split(',')[0].split(' ')\n",
    "    if len(a) == 1:\n",
    "        return a[0]\n",
    "    elif len(a) == 2:\n",
    "        return a[1]\n",
    "    elif len(a) == 3:\n",
    "        return a[2]\n",
    "    else:\n",
    "        return a[-1]\n",
    "\n",
    "df = data.copy()\n",
    "df = df[(df['Include'] == 1) & (df['BP Distribution Type'] == 'ME') & ((df['Evaluation Metric'] == 'MAE') | (df['Evaluation Metric'] == 'ME'))]\n",
    "\n",
    "df['Sensor Data'] = df['Key Devices and Measurements'].str.split(';', expand=True)[0]\n",
    "df['Calibration Technique'] = df['Calibration Technique'].str.split(';', expand=True)[0]\n",
    "df['Algorithm'] = df['Algorithm'].str.split(';', expand=True)[0]\n",
    "df['Dataset'] = df['Dataset'].str.split(';', expand=True)[0]\n",
    "df['Testing Subject Characteristics'] = df['Testing Subject Characteristics'].str.split(';', expand=True)[0]\n",
    "df['Study Characteristics'] = df['Study Characteristics'].str.split(';', expand=True)[0]\n",
    "df['Algorithm'] = df['Algorithm'].str.split(';', expand=True)[0]\n",
    "df['SBP Distribution Raw'] = df['BP Distribution'].str.split(';', expand=True)[0]\n",
    "df['SBP Distribution STD'] = df['SBP Distribution Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "df['DBP Distribution Raw'] = df['BP Distribution'].str.split(';', expand=True)[1]\n",
    "df['DBP Distribution STD'] = df['DBP Distribution Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "df['SBP Reported Error Raw'] = df['Reported Result'].str.split(';', expand=True)[0]\n",
    "df['DBP Reported Error Raw'] = df['Reported Result'].str.split(';', expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f140d87e-37aa-400e-b2c8-5094a346f2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/4128608041.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mae['SBP Error STD'] = df_mae['SBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/4128608041.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_mae['DBP Error STD'] = df_mae['DBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/4128608041.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_me['SBP Error STD'] = df_me['SBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/4128608041.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_me['DBP Error STD'] = df_me['DBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n"
     ]
    }
   ],
   "source": [
    "df_mae = df[df['Evaluation Metric'] == 'MAE']\n",
    "df_mae['SBP Error STD'] = df_mae['SBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
    "df_mae['DBP Error STD'] = df_mae['DBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
    "df_me = df[df['Evaluation Metric'] == 'ME']\n",
    "df_me['SBP Error STD'] = df_me['SBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "df_me['DBP Error STD'] = df_me['DBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "df_concat = pd.concat([df_me, df_mae], axis=0)\n",
    "df_concat['SBP ED'] = df_concat['SBP Distribution STD']/df_concat['SBP Error STD']\n",
    "df_concat['DBP ED'] = df_concat['DBP Distribution STD']/df_concat['DBP Error STD']\n",
    "\n",
    "df_concat['SBP ED 95CI UB'] = df_concat.apply(lambda x: np.sqrt(stats.f.isf(0.05/2, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['SBP ED'], axis=1)\n",
    "df_concat['SBP ED 95CI LB'] = df_concat.apply(lambda x: np.sqrt(stats.f.isf(1-0.05/2, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['SBP ED'], axis=1)\n",
    "df_concat['SBP ED MOE'] = (df_concat['SBP ED 95CI UB'] - df_concat['SBP ED 95CI LB'])/2\n",
    "df_concat['DBP ED 95CI UB'] = df_concat.apply(lambda x: np.sqrt(stats.f.isf(0.05/2, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['DBP ED'], axis=1)\n",
    "df_concat['DBP ED 95CI LB'] = df_concat.apply(lambda x: np.sqrt(stats.f.isf(1-0.05/2, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['DBP ED'], axis=1)\n",
    "df_concat['DBP ED MOE'] = (df_concat['DBP ED 95CI UB'] - df_concat['DBP ED 95CI LB'])/2\n",
    "\n",
    "df_concat['Authors'] = df_concat['Authors'].apply(compress_authors) + ' et al.'\n",
    "compute_power = lambda x: TTestIndPower().solve_power(5/8, ratio=1, alpha=0.05, nobs1=x, power=None, alternative='two-sided')\n",
    "df_concat['Power'] = df_concat['Number of Test Subjects'].apply(compute_power)\n",
    "# 2*((stats.norm.isf(1-0.05/2) + stats.norm.isf(1-0.02))/(5/8))**2\n",
    "# 1-stats.norm.sf(np.sqrt(85/2)*(5/8)-stats.norm.ppf(1-0.05/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708b99a-ba69-49be-8719-e67f468e0bd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Subject Split and Personalization Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd82658-c5e9-4cf6-8ab3-96c5a68e5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = ['Title', 'ArticleURL', 'Authors', 'Year', 'Calibration Technique', 'Sensor Data', 'Algorithm', 'Dataset', 'Number of Test Subjects', 'Testing Subject Characteristics', 'Study Characteristics', 'SBP Distribution STD', 'DBP Distribution STD', 'Reported Result', 'SBP ED', 'DBP ED', 'SBP ED MOE', 'DBP ED MOE', 'Power', 'Original Model Implementation Availability', 'Original Model Implementation Link', 'Exact Dataset/Pre-processing Code Availability', 'Exact Dataset/Pre-processing Code Link']\n",
    "\n",
    "def make_clickable(name, url):\n",
    "    return '<a href=\"' + url + '\">' + name + '</a>'\n",
    "\n",
    "save_table = df_concat.copy()[save_cols]\n",
    "save_table['Title'] = make_clickable(save_table['Title'] + ' (' + save_table['Authors'] + ', '+ save_table['Year'].astype(int).astype(str) + ')', save_table['ArticleURL'])\n",
    "save_table.drop(['Year'], axis=1, inplace=True)\n",
    "save_table.drop(['Authors'], axis=1, inplace=True)\n",
    "save_table.drop(['ArticleURL'], axis=1, inplace=True)\n",
    "\n",
    "save_table['Original Model Implementation Availability'] = make_clickable(save_table['Original Model Implementation Availability'], save_table['Original Model Implementation Link'])\n",
    "save_table['Exact Dataset/Pre-processing Code Availability'] = make_clickable(save_table['Exact Dataset/Pre-processing Code Availability'], save_table['Exact Dataset/Pre-processing Code Link'])\n",
    "save_table.drop(['Original Model Implementation Link', 'Exact Dataset/Pre-processing Code Link'], axis=1, inplace=True)\n",
    "\n",
    "sls_save_table = save_table[save_table['Calibration Technique'] == 'subject split']\n",
    "per_save_table = save_table[save_table['Calibration Technique'] == 'personalization']\n",
    "\n",
    "save_table.to_html('./_includes/include_table.html', index=False, render_links=True, table_id='itable', escape=False)\n",
    "sls_save_table.to_html('./_includes/include_sls_table.html', index=False, render_links=True, table_id='islstable', escape=False)\n",
    "per_save_table.to_html('./_includes/include_per_table.html', index=False, render_links=True, table_id='ipertable', escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea2b16-5d1e-4e6c-bfc4-6bc5cd9d1cdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Interactive Metadata Statistics Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b369f1a-60e4-474b-aef3-29ddbb818735",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Sensor Data', 'Algorithm', 'Dataset', 'Testing Subject Characteristics', 'Study Characteristics']\n",
    "cont_columns = ['Number of Test Subjects', 'SBP Distribution STD', 'DBP Distribution STD', 'SBP ED', 'DBP ED', 'Power']\n",
    "\n",
    "tooltips = [(\"% of subject split\", \"@{subject split pct}\"), \n",
    "            (\"% of personalization\", \"@{personalization pct}\")]\n",
    "\n",
    "ps = []\n",
    "for c in cat_columns:\n",
    "    d = pd.DataFrame(save_table[[c, 'Calibration Technique']].value_counts()).reset_index().rename({0: 'Count'}, axis=1).pivot(index=c, columns='Calibration Technique', values='Count').reset_index().fillna(0)\n",
    "    d['subject split pct'] = d['subject split']/d['subject split'].sum()*100\n",
    "    d['personalization pct'] = d['personalization']/d['personalization'].sum()*100\n",
    "    d['total'] = d['subject split']+d['personalization']\n",
    "    d = d.sort_values(by='total')\n",
    "    source = ColumnDataSource(d)\n",
    "    p = Plot(title=None, width=800, height=600, toolbar_location=None)\n",
    "    p = figure(y_range=FactorRange(factors=d[c].unique()), plot_width=1000, plot_height=400, title='',\n",
    "                toolbar_location=None, tooltips=tooltips, tools = [])\n",
    "    p.hbar_stack(['subject split', 'personalization'], y=c, source=source, fill_color=['red', 'blue'])\n",
    "    p.x_range = Range1d(0, (d['subject split']+d['personalization']).max())\n",
    "    p.yaxis.axis_label = c\n",
    "    p.xaxis.axis_label = 'Number of Studies'\n",
    "    ps.append(p)\n",
    "    output_file('./_includes/' + c.replace(' ', '_') + '_stats.html')\n",
    "    show(p)\n",
    "\n",
    "for c in cont_columns:\n",
    "    d = save_table[[c, 'Calibration Technique']]\n",
    "    d1 = d[d['Calibration Technique'] == 'subject split'].dropna()\n",
    "    d2 = d[d['Calibration Technique'] == 'personalization'].dropna()\n",
    "    p1 = figure(title='Subject Split', width=500, height=400, min_border=0, tools='', background_fill_color=\"#fafafa\", toolbar_location='above')\n",
    "    p2 = figure(title='Personalization', width=500, height=400, min_border=0, tools=[], background_fill_color=\"#fafafa\", toolbar_location='above')\n",
    "    hist1, edge1 = np.histogram(d1[c], bins=10)\n",
    "    hist2, edge2 = np.histogram(d2[c], bins=10)\n",
    "    p1.quad(top=hist1, bottom=0, fill_color='red', line_color=\"white\", left=edge1[:-1], right=edge1[1:])\n",
    "    p2.quad(top=hist2, bottom=0, fill_color='blue', line_color=\"white\", left=edge2[:-1], right=edge2[1:])\n",
    "    \n",
    "    p1.y_range = Range1d(0, hist1.max())\n",
    "    p1.xaxis.axis_label = c\n",
    "    p1.yaxis.axis_label = 'Number of Studies'\n",
    "    p2.y_range = Range1d(0, hist2.max())\n",
    "    p2.xaxis.axis_label = c\n",
    "    p2.yaxis.axis_label = 'Number of Studies'\n",
    "    p = row(p1, p2)\n",
    "    ps.append(p)\n",
    "    output_file('./_includes/' + c.replace(' ', '_') + '_stats.html')\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "# tabs = []\n",
    "# for i in range(len(cat_columns)):\n",
    "#     tabs.append(Panel(child=ps[i], title=cat_columns[i]))\n",
    "# for i in range(len(cont_columns)):\n",
    "#     tabs.append(Panel(child=ps[len(cat_columns)+i], title=cont_columns[i]))\n",
    "# figure_tabs = Tabs(tabs=tabs)\n",
    "# output_file('./_includes/metadata_stats.html')\n",
    "# show(figure_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb861d4-3762-4b45-a3eb-926b7d8b3ed1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create Metadata Statistics for Paper Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b385e0-396d-4f9d-a2bd-76e40047080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Sensor Data', 'Algorithm', 'Dataset', 'Study Characteristics']\n",
    "\n",
    "tooltips = [(\"% of subject split\", \"@{subject split pct}\"), \n",
    "            (\"% of personalization\", \"@{personalization pct}\")]\n",
    "\n",
    "ps = []\n",
    "for c in cat_columns:\n",
    "    d = pd.DataFrame(save_table[[c, 'Calibration Technique']].value_counts()).reset_index().rename({0: 'Count'}, axis=1).pivot(index=c, columns='Calibration Technique', values='Count').reset_index().fillna(0)\n",
    "    d['subject split pct'] = d['subject split']/d['subject split'].sum()*100\n",
    "    d['personalization pct'] = d['personalization']/d['personalization'].sum()*100\n",
    "    source = ColumnDataSource(d)\n",
    "    p = Plot(title=None, width=800, height=600, toolbar_location=None)\n",
    "    p = figure(y_range=FactorRange(factors=d[c].unique()), plot_width=1000, plot_height=400, title='',\n",
    "                toolbar_location=None, tooltips=tooltips, tools = [])\n",
    "    p.hbar_stack(['subject split', 'personalization'], y=c, source=source, fill_color=['red', 'blue'])\n",
    "    p.x_range = Range1d(0, (d['subject split']+d['personalization']).max())\n",
    "    p.xaxis.axis_label = c\n",
    "    p.yaxis.axis_label = 'Count'\n",
    "    ps.append(p)\n",
    "\n",
    "for c in cont_columns:\n",
    "    d = save_table[[c, 'Calibration Technique']]\n",
    "    d1 = d[d['Calibration Technique'] == 'subject split'].dropna()\n",
    "    d2 = d[d['Calibration Technique'] == 'personalization'].dropna()\n",
    "    p1 = figure(title=c + ' (Subject Split)', width=500, height=400, min_border=0, tools='', background_fill_color=\"#fafafa\", toolbar_location='above')\n",
    "    p2 = figure(title=c + ' (Personalization)', width=500, height=400, min_border=0, tools=[], background_fill_color=\"#fafafa\", toolbar_location='above')\n",
    "    hist1, edge1 = np.histogram(d1[c], bins=10)\n",
    "    hist2, edge2 = np.histogram(d2[c], bins=10)\n",
    "    p1.quad(top=hist1, bottom=0, fill_color='red', line_color=\"white\", alpha=0.5, left=edge1[:-1], right=edge1[1:])\n",
    "    p2.quad(top=hist2, bottom=0, fill_color='blue', line_color=\"white\", alpha=0.5, left=edge2[:-1], right=edge2[1:])\n",
    "    \n",
    "    p1.y_range = Range1d(0, hist1.max())\n",
    "    p1.xaxis.axis_label = c\n",
    "    p1.yaxis.axis_label = 'Count'\n",
    "    p2.y_range = Range1d(0, hist2.max())\n",
    "    p2.xaxis.axis_label = c\n",
    "    p2.yaxis.axis_label = 'Count'\n",
    "    p = row(p1, p2)\n",
    "    ps.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e64cae0-4d33-49f0-994a-8c49d04af0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./_includes/metadata_stats_paperfig.html')\n",
    "grid = gridplot([[ps[0], ps[1]], [ps[2], ps[3]]], width=1000, height=600)\n",
    "grid.spacing = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "293635dd-11c7-4340-b70d-604dc66b7223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/matt/Documents/GRAD_SCHOOL/wearablebp.github.io/_includes/metadata_stats_paperfig.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bokeh.io import export_png\n",
    "export_png(grid, filename='./_includes/metadata_stats_paperfig.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48db3f-4382-426b-8aed-8e7ac57c367c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create ED Scatter Plots and generate includes, excludes, and meet specs tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2956f455-4a21-4bb3-87dc-070c7c16c8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2121789591.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meetspecs_sls['SBP ED 95CI LB'] = meetspecs_sls.apply(lambda x: np.sqrt(stats.f.isf(1-0.1, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['SBP ED'], axis=1)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2121789591.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meetspecs_sls['DBP ED 95CI LB'] = meetspecs_sls.apply(lambda x: np.sqrt(stats.f.isf(1-0.1, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['DBP ED'], axis=1)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2121789591.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meetspecs_sls[col] = np.round(meetspecs_sls[col], 2)\n"
     ]
    }
   ],
   "source": [
    "meetspecs_sls = sls_save_table[(sls_save_table['Power'] > 0.98) & (sls_save_table['SBP ED'] > 2.17) & (sls_save_table['DBP ED'] > 1.39)]\n",
    "meetspecs_sls['SBP ED 95CI LB'] = meetspecs_sls.apply(lambda x: np.sqrt(stats.f.isf(1-0.1, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['SBP ED'], axis=1)\n",
    "meetspecs_sls['DBP ED 95CI LB'] = meetspecs_sls.apply(lambda x: np.sqrt(stats.f.isf(1-0.1, x['Number of Test Subjects']-1, x['Number of Test Subjects']-1))*x['DBP ED'], axis=1)\n",
    "meetspecs_cols = ['Title', 'Sensor Data', 'Calibration Technique', 'Algorithm', 'Dataset', 'SBP ED', 'DBP ED', 'SBP ED 95CI LB', 'DBP ED 95CI LB']\n",
    "for col in meetspecs_sls.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns:\n",
    "    meetspecs_sls[col] = np.round(meetspecs_sls[col], 2)\n",
    "meetspecs_sls[meetspecs_cols].to_html('./_includes/meetspecs_sls_table.html', index=False, render_links=True, table_id='mslstable', escape=False)\n",
    "\n",
    "# per_save_table[(per_save_table['Power'] > 0.98) & (per_save_table['SBP ED'] - per_save_table['SBP ED MOE'] > 2.17) & (per_save_table['DBP ED'] - per_save_table['DBP ED MOE'] > 1.39)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b88787c-cc35-4ddc-8840-10f2d749af66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2903807737.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exclude_table['Year'] = exclude_table['Year'].fillna(0)\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2903807737.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exclude_table['Authors'] = exclude_table['Authors'].fillna('Not Available')\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2903807737.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exclude_table['Title'] = make_clickable(exclude_table['Title'] + ' ' + exclude_table['Year'].astype(int).astype(str), exclude_table['ArticleURL'])\n",
      "/var/folders/4k/jr4_f2px17b2sdv74jmvp4x80000gn/T/ipykernel_25023/2903807737.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exclude_table['Authors'] = exclude_table['Authors'].apply(compress_authors) + ' et al.'\n"
     ]
    }
   ],
   "source": [
    "# get exclude table\n",
    "exclude_table = data[data['Include'] == 0]\n",
    "exclude_table['Year'] = exclude_table['Year'].fillna(0)\n",
    "exclude_table['Authors'] = exclude_table['Authors'].fillna('Not Available')\n",
    "exclude_table['Title'] = make_clickable(exclude_table['Title'] + ' ' + exclude_table['Year'].astype(int).astype(str), exclude_table['ArticleURL'])\n",
    "exclude_table['Authors'] = exclude_table['Authors'].apply(compress_authors) + ' et al.'\n",
    "exclude_table = exclude_table[['Title', 'Authors', 'Exclude Reason']]\n",
    "exclude_table.to_html('./_includes/exclude_table.html', index=False, render_links=True, table_id='etable', escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feb5c592-e9f5-46d4-b171-07229d89511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 20px\"> @{Hover Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> @{Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Sensor Data: @{Sensor Data}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP/DBP Reported Result (mmHg): @{SBP Reported Error Raw} /  @{DBP Reported Error Raw} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Explained Deviation: @{SBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Explained Deviation: @{DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Distribution STD: @{SBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Distribution STD: @{DBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Power: @{Power}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Number of Test Subjects: @{Number of Test Subjects}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Study Characteristics: @{Study Characteristics}</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb521d8-87c2-423f-af05-8a8f0afe7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df_sls = sls_save_table[sls_save_table['Calibration Technique'] == 'subject split'].dropna(subset=['SBP ED', 'DBP ED'], axis=0)\n",
    "Y = plot_df_sls['SBP ED']\n",
    "X = plot_df_sls['DBP ED']\n",
    "plot_df_sls_x = np.linspace(X.min(), X.max(), 100)\n",
    "plot_df_sls_x = sm.add_constant(plot_df_sls_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "sls_params = results.params.values\n",
    "sls_pval = results.pvalues[1]\n",
    "sls_y = results.predict(plot_df_sls_x)\n",
    "sls_x = plot_df_sls_x[:, 1]\n",
    "sls_ci = results.conf_int().values[1, :]\n",
    "\n",
    "plot_df_per = per_save_table[per_save_table['Calibration Technique'] == 'personalization'].dropna(subset=['SBP ED', 'DBP ED'], axis=0)\n",
    "Y = plot_df_per['SBP ED']\n",
    "X = plot_df_per['DBP ED']\n",
    "plot_df_per_x = np.linspace(X.min(), X.max(), 100)\n",
    "plot_df_per_x = sm.add_constant(plot_df_per_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_params = results.params.values\n",
    "per_pval = results.pvalues[1]\n",
    "per_y = results.predict(plot_df_per_x)\n",
    "per_x = plot_df_per_x[:, 1]\n",
    "per_ci = results.conf_int().values[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf8bdae-033b-4d12-b022-27664d069bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file('./_includes/scatter.html')\n",
    "\n",
    "p1 = figure(title='Subject Split', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p1.xaxis.axis_label = 'DBP Explained Deviation'\n",
    "p1.yaxis.axis_label = 'SBP Explained Deviation'\n",
    "p2 = figure(title='Personalization', background_fill_color=\"#fafafa\", width=625, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p2.xaxis.axis_label = 'DBP Explained Deviation'\n",
    "p2.yaxis.axis_label = 'SBP Explained Deviation'\n",
    "\n",
    "box = BoxAnnotation(bottom=2.17, left=1.39, fill_alpha=0.05, fill_color='green', line_width=5, line_dash = 'dashed', line_color='green', line_alpha=0.05)\n",
    "p1.add_layout(box)\n",
    "p2.add_layout(box)\n",
    "\n",
    "plot_df = df_concat.copy()\n",
    "\n",
    "colors = {}\n",
    "u_sd = plot_df['Sensor Data'].unique()\n",
    "for i in range(len(u_sd)):\n",
    "    colors[u_sd[i]] = cs[i]\n",
    "plot_df['Color'] = [colors[i] for i in plot_df['Sensor Data']]\n",
    "plot_df['Size'] = plot_df['Power']*15\n",
    "plot_df['Hover Title'] = plot_df['Authors'] + ' (' + plot_df['Year'].astype(int).astype(str) + ')'\n",
    "\n",
    "legend_it = []\n",
    "for i in range(len(u_sd)):\n",
    "    d1 = plot_df[plot_df['Sensor Data'] == u_sd[i]]\n",
    "    sls = d1[d1['Calibration Technique'] == 'subject split']\n",
    "    per = d1[d1['Calibration Technique'] == 'personalization']\n",
    "    c1 = p1.scatter('DBP ED', 'SBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c2 = p2.scatter('DBP ED', 'SBP ED', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c3 = p2.scatter('DBP ED', 'SBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "    taptool1 = p1.select(type=TapTool)\n",
    "    taptool1.callback = OpenURL(url='@ArticleURL')\n",
    "    taptool2 = p2.select(type=TapTool)\n",
    "    taptool2.callback = OpenURL(url='@ArticleURL')\n",
    "    legend_it.append((u_sd[i], [c1, c2, c3]))\n",
    "    legend = Legend(items=legend_it)\n",
    "    legend.click_policy='mute'\n",
    "\n",
    "c100 = p1.line(sls_x, sls_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(sls_params[1]) + ' (CI = [' + \"{:.3f}\".format(sls_ci[0]) + ', ' + \"{:.3f}\".format(sls_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(sls_pval) + '*)')\n",
    "# c101 = p2.line(per_x, per_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_ci[0]) + ', ' + \"{:.3f}\".format(per_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_pval) + ')')\n",
    "    \n",
    "p2.add_layout(legend, 'right')\n",
    "# p1.add_layout(legend, 'right')\n",
    "\n",
    "show(row([p1, p2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2266f1-044b-40b5-b7c3-38a953f33ca7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Create Code Availability Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85eb57f8-5147-42f4-8f5d-53866dfe41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cols = ['Title', 'Authors', 'ArticleURL', 'Year', 'Sensor Data', 'Number of Test Subjects', 'Dataset', 'Calibration Technique', 'SBP ED', 'DBP ED', 'Original Model Implementation Availability', 'Original Model Implementation Link', 'Exact Dataset/Pre-processing Code Availability', 'Exact Dataset/Pre-processing Code Link', 'wearablebp.github.io Implementation Result']\n",
    "availability_table = df_concat.copy()[save_cols]\n",
    "availability_table['Title'] = make_clickable(availability_table['Title'] + ' (' + availability_table['Authors'] + ', ' + availability_table['Year'].astype(int).astype(str) + ')', availability_table['ArticleURL'])\n",
    "# availability_table.drop('ArticleURL', axis=1, inplace=True)\n",
    "\n",
    "availability_table['Original Model Implementation Availability'] = make_clickable(availability_table['Original Model Implementation Availability'], availability_table['Original Model Implementation Link'])\n",
    "availability_table['Exact Dataset/Pre-processing Code Availability'] = make_clickable(availability_table['Exact Dataset/Pre-processing Code Availability'], availability_table['Exact Dataset/Pre-processing Code Link'])\n",
    "\n",
    "availability_table[['Title', 'Sensor Data', 'Dataset', 'Calibration Technique', 'SBP ED', 'DBP ED', 'Original Model Implementation Availability', 'Exact Dataset/Pre-processing Code Availability', ]].rename({'SBP ED':'Reported SBP ED', 'DBP ED': 'Reported DBP ED'}, axis=1).to_html('./_includes/availability_table.html', index=False, render_links=True, table_id='atable', escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80fa987-4dbd-4db3-8b08-ecfc38d9463c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Other paper plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624e60d-3305-4abe-88c5-1870bf885f90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## STD vs SBP/DBP ED\n",
    "\n",
    "Publication bias: since AAMI standards require <5±8mmHg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107f1e7c-d12d-45db-bcc1-3e380865f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "Y = plot_df[plot_df['Calibration Technique'] == 'subject split']['SBP ED']\n",
    "X = plot_df[plot_df['Calibration Technique'] == 'subject split']['SBP Distribution STD']\n",
    "sls_sbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "sls_sbp_x = sm.add_constant(sls_sbp_x)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "sls_sbp_params = results.params.values\n",
    "sls_sbp_pval = results.pvalues[1]\n",
    "sls_sbp_y = results.predict(sls_sbp_x)\n",
    "sls_sbp_x = sls_sbp_x[:, 1]\n",
    "sls_sbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "dbp_plot_df = plot_df.dropna(subset=['DBP Distribution STD', 'DBP ED'], axis=0)\n",
    "Y = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'subject split']['DBP ED']\n",
    "X = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'subject split']['DBP Distribution STD']\n",
    "sls_dbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "sls_dbp_x = sm.add_constant(sls_dbp_x)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "sls_dbp_params = results.params.values\n",
    "sls_dbp_pval = results.pvalues[1]\n",
    "sls_dbp_y = results.predict(sls_dbp_x)\n",
    "sls_dbp_x = sls_dbp_x[:, 1]\n",
    "sls_dbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "Y = plot_df[plot_df['Calibration Technique'] == 'personalization']['SBP ED']\n",
    "X = plot_df[plot_df['Calibration Technique'] == 'personalization']['SBP Distribution STD']\n",
    "per_sbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_sbp_x = sm.add_constant(per_sbp_x)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_sbp_params = results.params.values\n",
    "per_sbp_pval = results.pvalues[1]\n",
    "per_sbp_y = results.predict(per_sbp_x)\n",
    "per_sbp_x = per_sbp_x[:, 1]\n",
    "per_sbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "dbp_plot_df = plot_df.dropna(subset=['DBP Distribution STD', 'DBP ED'], axis=0)\n",
    "Y = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'personalization']['DBP ED']\n",
    "X = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'personalization']['DBP Distribution STD']\n",
    "per_dbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_dbp_x = sm.add_constant(per_dbp_x)\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_dbp_params = results.params.values\n",
    "per_dbp_pval = results.pvalues[1]\n",
    "per_dbp_y = results.predict(per_dbp_x)\n",
    "per_dbp_x = per_dbp_x[:, 1]\n",
    "per_dbp_ci = results.conf_int().values[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1821b31-e1ef-4850-bd2f-1fab3fd5fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./_includes/scatter_std_ed.html')\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 20px\"> @{Hover Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> @{Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Sensor Data: @{Sensor Data}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP/DBP Reported Result (mmHg): @{SBP Reported Error Raw} /  @{DBP Reported Error Raw} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Explained Deviation: @{SBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Explained Deviation: @{DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Distribution STD: @{SBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Distribution STD: @{DBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Power: @{Power}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Number of Test Subjects: @{Number of Test Subjects}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Study Characteristics: @{Study Characteristics}</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']\n",
    "\n",
    "p3 = figure(title='Subject Split', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p3.xaxis.axis_label = 'SBP Distribution STD (mmHg)'\n",
    "p3.yaxis.axis_label = 'SBP Explained Deviation'\n",
    "p4 = figure(title='Personalization', background_fill_color=\"#fafafa\", width=645, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p4.xaxis.axis_label = 'SBP Distribution STD (mmHg)'\n",
    "p4.yaxis.axis_label = ''\n",
    "\n",
    "p5 = figure(title='', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p5.xaxis.axis_label = 'DBP Distribution STD (mmHg)'\n",
    "p5.yaxis.axis_label = 'DBP Explained Deviation'\n",
    "p6 = figure(title='', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p6.xaxis.axis_label = 'DBP Distribution STD (mmHg)'\n",
    "p6.yaxis.axis_label = ''\n",
    "\n",
    "box1 = BoxAnnotation(bottom=2.17, left=17.36, fill_alpha=0.05, fill_color='green', line_width=5, line_dash = 'dashed', line_color='green', line_alpha=0.05)\n",
    "box2 = BoxAnnotation(bottom=1.39, left=11.09, fill_alpha=0.05, fill_color='green', line_width=5, line_dash = 'dashed', line_color='green', line_alpha=0.05)\n",
    "p3.add_layout(box1)\n",
    "p4.add_layout(box1)\n",
    "p5.add_layout(box2)\n",
    "p6.add_layout(box2)\n",
    "\n",
    "plot_df = df_concat.copy()\n",
    "\n",
    "colors = {}\n",
    "u_sd = plot_df['Sensor Data'].unique()\n",
    "for i in range(len(u_sd)):\n",
    "    colors[u_sd[i]] = cs[i]\n",
    "plot_df['Color'] = [colors[i] for i in plot_df['Sensor Data']]\n",
    "plot_df['Size'] = plot_df['Power']*15\n",
    "plot_df['Hover Title'] = plot_df['Authors'] + ' (' + plot_df['Year'].astype(int).astype(str) + ')'\n",
    "\n",
    "legend_it1 = []\n",
    "legend_it2 = []\n",
    "for i in range(len(u_sd)):\n",
    "    d1 = plot_df[plot_df['Sensor Data'] == u_sd[i]]\n",
    "    sls = d1[d1['Calibration Technique'] == 'subject split']\n",
    "    per = d1[d1['Calibration Technique'] == 'personalization']\n",
    "    c4 = p3.scatter('SBP Distribution STD', 'SBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c5 = p4.scatter('SBP Distribution STD', 'SBP ED', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c6 = p4.scatter('SBP Distribution STD', 'SBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "    taptool1 = p3.select(type=TapTool)\n",
    "    taptool1.callback = OpenURL(url='@ArticleURL')\n",
    "    taptool2 = p4.select(type=TapTool)\n",
    "    taptool2.callback = OpenURL(url='@ArticleURL')\n",
    "    \n",
    "    c7 = p5.scatter('DBP Distribution STD', 'DBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c8 = p6.scatter('DBP Distribution STD', 'DBP ED', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c9 = p6.scatter('DBP Distribution STD', 'DBP ED', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "    taptool3 = p5.select(type=TapTool)\n",
    "    taptool3.callback = OpenURL(url='@ArticleURL')\n",
    "    taptool4 = p6.select(type=TapTool)\n",
    "    taptool4.callback = OpenURL(url='@ArticleURL')\n",
    "    \n",
    "    legend_it1.append((u_sd[i], [c4, c5, c6, c7, c8, c9]))\n",
    "    legend1 = Legend(items=legend_it1)\n",
    "    legend1.click_policy='mute'\n",
    "\n",
    "c10 = p3.line(sls_sbp_x, sls_sbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(sls_sbp_params[1]) + '(CI = [' + \"{:.3f}\".format(sls_sbp_ci[0]) + ', ' + \"{:.3f}\".format(sls_sbp_ci[1]) + '], ' +'p=' + \"{:.1e}\".format(sls_sbp_pval) + '*)')\n",
    "c11 = p4.line(per_sbp_x, per_sbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_sbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_sbp_ci[0]) + ', ' + \"{:.3f}\".format(per_sbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_sbp_pval) + '*)')\n",
    "c12 = p5.line(sls_dbp_x, sls_dbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(sls_dbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(sls_dbp_ci[0]) + ', ' + \"{:.3f}\".format(sls_dbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(sls_dbp_pval) + '*)')\n",
    "c13 = p6.line(per_dbp_x, per_dbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_dbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_dbp_ci[0]) + ', ' + \"{:.3f}\".format(per_dbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_dbp_pval) + '*)')\n",
    "    \n",
    "p4.add_layout(legend1, 'right')\n",
    "# p6.add_layout(legend2, 'right')\n",
    "# p1.add_layout(legend, 'right')\n",
    "\n",
    "\n",
    "show(column(row([p3, p4]), row([p5, p6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4d653c-1c21-4057-aa0e-8088635aa765",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Error vs STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14ec5ff1-fe4d-4e22-8514-dac607d82746",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = plot_df[plot_df['Calibration Technique'] == 'subject split']['SBP Error STD']\n",
    "X = plot_df[plot_df['Calibration Technique'] == 'subject split']['SBP Distribution STD']\n",
    "sls_sbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "sls_sbp_x = sm.add_constant(sls_sbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "sls_sbp_params = results.params.values\n",
    "sls_sbp_pval = results.pvalues[1]\n",
    "sls_sbp_y = results.predict(sls_sbp_x)\n",
    "sls_sbp_x = sls_sbp_x[:, 1]\n",
    "sls_sbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "dbp_plot_df = plot_df.dropna(subset=['DBP Distribution STD', 'DBP Error STD'], axis=0)\n",
    "Y = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'subject split']['DBP Error STD']\n",
    "X = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'subject split']['DBP Distribution STD']\n",
    "sls_dbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "sls_dbp_x = sm.add_constant(sls_dbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "sls_dbp_params = results.params.values\n",
    "sls_dbp_pval = results.pvalues[1]\n",
    "sls_dbp_y = results.predict(sls_dbp_x)\n",
    "sls_dbp_x = sls_dbp_x[:, 1]\n",
    "sls_dbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "Y = plot_df[plot_df['Calibration Technique'] == 'personalization']['SBP Error STD']\n",
    "X = plot_df[plot_df['Calibration Technique'] == 'personalization']['SBP Distribution STD']\n",
    "per_sbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_sbp_x = sm.add_constant(per_sbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_sbp_params = results.params.values\n",
    "per_sbp_pval = results.pvalues[1]\n",
    "per_sbp_y = results.predict(per_sbp_x)\n",
    "per_sbp_x = per_sbp_x[:, 1]\n",
    "per_sbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "dbp_plot_df = plot_df.dropna(subset=['DBP Distribution STD', 'DBP Error STD'], axis=0)\n",
    "Y = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'personalization']['DBP Error STD']\n",
    "X = dbp_plot_df[dbp_plot_df['Calibration Technique'] == 'personalization']['DBP Distribution STD']\n",
    "per_dbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_dbp_x = sm.add_constant(per_dbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_dbp_params = results.params.values\n",
    "per_dbp_pval = results.pvalues[1]\n",
    "per_dbp_y = results.predict(per_dbp_x)\n",
    "per_dbp_x = per_dbp_x[:, 1]\n",
    "per_dbp_ci = results.conf_int().values[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0571e57-cc9e-491d-ba78-fdf5d67d42b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG 4\n",
      "ECG+PPG 15\n",
      "PPG+PPG 5\n",
      "BCG+PPG 1\n",
      "PPG 15\n",
      "PPG+pressure sensor 1\n",
      "biometrics+pressure 1\n",
      "pressure+multi-wavelength PPG 1\n",
      "biometrics+PPG 3\n",
      "pressure+PPG 2\n",
      "ECG+PCG+PPG 3\n",
      "      SBP Distribution STD  SBP Error STD\n",
      "1539                  7.95            6.6\n",
      "1630                 20.00            6.3\n",
      "1631                 12.90            6.3\n",
      "pressure sensor 1\n",
      "biometrics+ECG+PPG 1\n",
      "ICG 2\n",
      "ultrasound 2\n",
      "biometrics+PCG 1\n",
      "PPG+SCG 1\n",
      "ECG+ICG+PPG 1\n"
     ]
    }
   ],
   "source": [
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 20px\"> @{Hover Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> @{Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Sensor Data: @{Sensor Data}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP/DBP Reported Result (mmHg): @{SBP Reported Error Raw} /  @{DBP Reported Error Raw} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Explained Deviation: @{SBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Explained Deviation: @{DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Distribution STD: @{SBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Distribution STD: @{DBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Power: @{Power}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Number of Test Subjects: @{Number of Test Subjects}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Study Characteristics: @{Study Characteristics}</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']\n",
    "\n",
    "p203 = figure(title='Subject Split', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p203.xaxis.axis_label = 'SBP Distribution STD (mmHg)'\n",
    "p203.yaxis.axis_label = 'SBP Error STD (mmHg)'\n",
    "# p4 = figure(title='Personalization', background_fill_color=\"#fafafa\", width=645, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "# p4.xaxis.axis_label = 'SBP Distribution STD (mmHg)'\n",
    "# p4.yaxis.axis_label = ''\n",
    "\n",
    "# p205 = figure(title='', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p205 = figure(title='', background_fill_color=\"#fafafa\", width=625, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p205.xaxis.axis_label = 'DBP Distribution STD (mmHg)'\n",
    "p205.yaxis.axis_label = 'DBP Error STD (mmHg)'\n",
    "# p6 = figure(title='', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "# p6.xaxis.axis_label = 'DBP Distribution STD (mmHg)'\n",
    "# p6.yaxis.axis_label = ''\n",
    "\n",
    "# box1 = BoxAnnotation(top=8, left=17.36, fill_alpha=0.05, fill_color='green', line_width=5, line_dash = 'dashed', line_color='green', line_alpha=0.05)\n",
    "# box2 = BoxAnnotation(top=8, left=11.09, fill_alpha=0.05, fill_color='green', line_width=5, line_dash = 'dashed', line_color='green', line_alpha=0.05)\n",
    "# p203.add_layout(box1)\n",
    "# p4.add_layout(box1)\n",
    "# p205.add_layout(box2)\n",
    "# p6.add_layout(box2)\n",
    "\n",
    "plot_df = df_concat.copy()\n",
    "\n",
    "colors = {}\n",
    "u_sd = plot_df['Sensor Data'].unique()\n",
    "for i in range(len(u_sd)):\n",
    "    colors[u_sd[i]] = cs[i]\n",
    "plot_df['Color'] = [colors[i] for i in plot_df['Sensor Data']]\n",
    "plot_df['Size'] = plot_df['Power']*15\n",
    "plot_df['Hover Title'] = plot_df['Authors'] + ' (' + plot_df['Year'].astype(int).astype(str) + ')'\n",
    "\n",
    "legend_it201 = []\n",
    "for i in range(len(u_sd)):\n",
    "    d1 = plot_df[plot_df['Sensor Data'] == u_sd[i]]\n",
    "    sls = d1[d1['Calibration Technique'] == 'subject split'].dropna(subset=['Sensor Data'])\n",
    "    per = d1[d1['Calibration Technique'] == 'personalization']\n",
    "    if len(sls) > 0:\n",
    "        print(u_sd[i], len(sls))\n",
    "        if u_sd[i] == 'ECG+PCG+PPG':\n",
    "            print(sls[['SBP Distribution STD', 'SBP Error STD']])\n",
    "        c204 = p203.scatter('SBP Distribution STD', 'SBP Error STD', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "        # c5 = p4.scatter('SBP Distribution STD', 'SBP Error STD', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "        # c6 = p4.scatter('SBP Distribution STD', 'SBP Error STD', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "        taptool1 = p203.select(type=TapTool)\n",
    "        taptool1.callback = OpenURL(url='@ArticleURL')\n",
    "        # taptool2 = p4.select(type=TapTool)\n",
    "        # taptool2.callback = OpenURL(url='@ArticleURL')\n",
    "\n",
    "        c207 = p205.scatter('DBP Distribution STD', 'DBP Error STD', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "        # c8 = p6.scatter('DBP Distribution STD', 'DBP Error STD', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "        # c9 = p6.scatter('DBP Distribution STD', 'DBP Error STD', source=ColumnDataSource(sls), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "        taptool3 = p205.select(type=TapTool)\n",
    "        taptool3.callback = OpenURL(url='@ArticleURL')\n",
    "        # taptool4 = p6.select(type=TapTool)\n",
    "        # taptool4.callback = OpenURL(url='@ArticleURL')\n",
    "\n",
    "        # legend_it201.append((u_sd[i], [c204, c5, c6, c207, c8, c9]))\n",
    "        legend_it201.append((u_sd[i], [c204, c207]))\n",
    "        legend201 = Legend(items=legend_it201)\n",
    "        legend201.click_policy='mute'\n",
    "    \n",
    "c10 = p203.line(sls_sbp_x, sls_sbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(sls_sbp_params[1]) + '(CI = [' + \"{:.3f}\".format(sls_sbp_ci[0]) + ', ' + \"{:.3f}\".format(sls_sbp_ci[1]) + '], ' +'p=' + \"{:.1e}\".format(sls_sbp_pval) + '*)')\n",
    "# c11 = p4.line(per_sbp_x, per_sbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_sbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_sbp_ci[0]) + ', ' + \"{:.3f}\".format(per_sbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_sbp_pval) + ')')\n",
    "c12 = p205.line(sls_dbp_x, sls_dbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(sls_dbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(sls_dbp_ci[0]) + ', ' + \"{:.3f}\".format(sls_dbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(sls_dbp_pval) + '*)')\n",
    "# c13 = p6.line(per_dbp_x, per_dbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_dbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_dbp_ci[0]) + ', ' + \"{:.3f}\".format(per_dbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_dbp_pval) + ')')\n",
    "    \n",
    "p205.add_layout(legend201, 'right')\n",
    "# p6.add_layout(legend2, 'right')\n",
    "# p1.add_layout(legend, 'right')\n",
    "\n",
    "\n",
    "# show(row([p203, p205]), row([p205, p6])))\n",
    "output_file('./_includes/scatter_std_err.html')\n",
    "show(row([p203, p205]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb3900-2f51-4da8-9754-06eb24d1a4d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time vs Accuracy Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f577844-819e-4578-920b-4b571c1136b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dt(x):\n",
    "    if 's' in x:\n",
    "        if x.split('s')[0] == '0':\n",
    "            return 0\n",
    "        return np.log10(int(x.split('s')[0]))+0\n",
    "    elif 'm' in x:\n",
    "        return np.log10(int(x.split('m')[0]))+1\n",
    "    elif 'h' in x:\n",
    "        return np.log10(int(x.split('h')[0]))+2\n",
    "    elif 'd' in x:\n",
    "        return np.log10(int(x.split('d')[0]))+3\n",
    "    elif 'mon' in x:\n",
    "        return np.log10(int(x.split('mon')[0]))+4\n",
    "\n",
    "per = data[(data['Include'] == 1) & (data['Study Characteristics'].str.contains('observational')) & (data['Time between Calibration and Test'].str.contains('unclear') == False) & (data['Time between Calibration and Test'].str.contains('heart beats') == False) & ((data['Evaluation Metric'] == 'MAE') | (data['Evaluation Metric'] == 'ME'))]\n",
    "per['Calibration Technique'] = per['Calibration Technique'].str.split(';', expand=True)[0]\n",
    "per = per[per['Calibration Technique'] == 'personalization']\n",
    "per['log_dt'] = per['Time between Calibration and Test'].apply(convert_dt)\n",
    "\n",
    "per['Sensor Data'] = per['Key Devices and Measurements'].str.split(';', expand=True)[0]\n",
    "per['Calibration Technique'] = per['Calibration Technique'].str.split(';', expand=True)[0]\n",
    "per['Algorithm'] = per['Algorithm'].str.split(';', expand=True)[0]\n",
    "per['Dataset'] = per['Dataset'].str.split(';', expand=True)[0]\n",
    "per['Testing Subject Characteristics'] = per['Testing Subject Characteristics'].str.split(';', expand=True)[0]\n",
    "per['Study Characteristics'] = per['Study Characteristics'].str.split(';', expand=True)[0]\n",
    "per['Algorithm'] = per['Algorithm'].str.split(';', expand=True)[0]\n",
    "per['SBP Distribution Raw'] = per['BP Distribution'].str.split(';', expand=True)[0]\n",
    "per['SBP Distribution STD'] = per['SBP Distribution Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "per['DBP Distribution Raw'] = per['BP Distribution'].str.split(';', expand=True)[1]\n",
    "per['DBP Distribution STD'] = per['DBP Distribution Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "per['SBP Reported Error Raw'] = per['Reported Result'].str.split(';', expand=True)[0]\n",
    "per['DBP Reported Error Raw'] = per['Reported Result'].str.split(';', expand=True)[1]\n",
    "\n",
    "per_mae = per[per['Evaluation Metric'] == 'MAE']\n",
    "per_mae['SBP Error STD'] = per_mae['SBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
    "per_mae['DBP Error STD'] = per_mae['DBP Reported Error Raw'].astype(float)*np.sqrt(pi/2)\n",
    "per_me = per[per['Evaluation Metric'] == 'ME']\n",
    "per_me['SBP Error STD'] = per_me['SBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "per_me['DBP Error STD'] = per_me['DBP Reported Error Raw'].str.split('±', expand=True)[1].astype(float)\n",
    "per_concat = pd.concat([per_me, per_mae], axis=0)\n",
    "per_concat['SBP ED'] = per_concat['SBP Distribution STD']/per_concat['SBP Error STD']\n",
    "per_concat['DBP ED'] = per_concat['DBP Distribution STD']/per_concat['DBP Error STD']\n",
    "\n",
    "per_concat['Number of Test Subjects'] = per_concat['Number of Test Subjects'].replace({'unclear': np.NaN})\n",
    "per_concat = per_concat.dropna(subset=['Number of Test Subjects'])\n",
    "per_concat['Power'] = per_concat['Number of Test Subjects'].astype(float).apply(compute_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd367a83-3c15-4aad-8f00-baff5253b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_concat_sbp = per_concat.dropna(subset=['SBP Error STD', 'log_dt'], axis=0)\n",
    "per_concat_sbp = per_concat_sbp[per_concat_sbp['log_dt'] > 0]\n",
    "Y = per_concat_sbp['SBP Error STD']\n",
    "X = per_concat_sbp['log_dt']\n",
    "per_sbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_sbp_x = sm.add_constant(per_sbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_sbp_params = results.params.values\n",
    "per_sbp_pval = results.pvalues[1]\n",
    "per_sbp_y = results.predict(per_sbp_x)\n",
    "per_sbp_x = per_sbp_x[:, 1]\n",
    "per_sbp_ci = results.conf_int().values[1, :]\n",
    "\n",
    "per_concat_dbp = per_concat.dropna(subset=['DBP Error STD', 'log_dt'], axis=0)\n",
    "per_concat_dbp = per_concat_dbp[per_concat_dbp['log_dt'] > 0]\n",
    "Y = per_concat_dbp['DBP Error STD']\n",
    "X = per_concat_dbp['log_dt']\n",
    "per_dbp_x = np.linspace(X.min(), X.max(), 100)\n",
    "per_dbp_x = sm.add_constant(per_dbp_x)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model = sm.OLS(Y,X)\n",
    "results = model.fit()\n",
    "per_dbp_params = results.params.values\n",
    "per_dbp_pval = results.pvalues[1]\n",
    "per_dbp_y = results.predict(per_dbp_x)\n",
    "per_dbp_x = per_dbp_x[:, 1]\n",
    "per_dbp_ci = results.conf_int().values[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23133e50-5a29-474b-9fbf-6727d0379b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file('./_includes/scatter_time.html')\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 20px\"> @{Hover Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> @{Title} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Sensor Data: @{Sensor Data}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP/DBP Reported Result (mmHg): @{SBP Reported Error Raw} /  @{DBP Reported Error Raw} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Explained Deviation: @{SBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Explained Deviation: @{DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP Distribution STD: @{SBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> DBP Distribution STD: @{DBP Distribution STD} mmHg </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Power: @{Power}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Number of Test Subjects: @{Number of Test Subjects}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Study Characteristics: @{Study Characteristics}</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']\n",
    "\n",
    "p10 = figure(title='', background_fill_color=\"#fafafa\", width=400, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p10.xaxis.axis_label = 'Time between calibration and test'\n",
    "p10.yaxis.axis_label = 'SBP Error STD (mmHg)'\n",
    "\n",
    "p11 = figure(title='', background_fill_color=\"#fafafa\", width=645, height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p11.xaxis.axis_label = 'Time between calibration and test'\n",
    "p11.yaxis.axis_label = 'DBP Error STD (mmHg)'\n",
    "\n",
    "plot_df = per_concat.copy()\n",
    "\n",
    "colors = {}\n",
    "u_sd = plot_df['Sensor Data'].unique()\n",
    "for i in range(len(u_sd)):\n",
    "    colors[u_sd[i]] = cs[i]\n",
    "plot_df['Color'] = [colors[i] for i in plot_df['Sensor Data']]\n",
    "plot_df['Size'] = plot_df['Power']*15\n",
    "plot_df['Hover Title'] = plot_df['Authors'] + ' (' + plot_df['Year'].astype(int).astype(str) + ')'\n",
    "\n",
    "legend_it1 = []\n",
    "for i in range(len(u_sd)):\n",
    "    d1 = plot_df[plot_df['Sensor Data'] == u_sd[i]]\n",
    "    per = d1[d1['Calibration Technique'] == 'personalization']\n",
    "    c4 = p10.scatter('log_dt', 'SBP Error STD', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c5 = p11.scatter('log_dt', 'SBP Error STD', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0)\n",
    "    c6 = p11.scatter('log_dt', 'DBP Error STD', source=ColumnDataSource(per), fill_alpha=0.4, size='Size', color='Color', muted_alpha=0, visible = False)\n",
    "    taptool1 = p10.select(type=TapTool)\n",
    "    taptool1.callback = OpenURL(url='@ArticleURL')\n",
    "    taptool2 = p11.select(type=TapTool)\n",
    "    taptool2.callback = OpenURL(url='@ArticleURL')\n",
    "\n",
    "    legend_it1.append((u_sd[i], [c4, c5, c6]))\n",
    "    legend1 = Legend(items=legend_it1)\n",
    "    legend1.click_policy='mute'\n",
    "\n",
    "# c10 = p10.line(per_sbp_x, per_sbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_sbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_sbp_ci[0]) + ', ' + \"{:.3f}\".format(per_sbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_sbp_pval) + ')')\n",
    "# c11 = p11.line(per_dbp_x, per_dbp_y, line_width=3, legend_label='Slope=' + \"{:.3f}\".format(per_dbp_params[1]) + ' (CI = [' + \"{:.3f}\".format(per_dbp_ci[0]) + ', ' + \"{:.3f}\".format(per_dbp_ci[1]) + '], ' + 'p=' + \"{:.1e}\".format(per_dbp_pval) + ')')\n",
    "    \n",
    "p11.add_layout(legend1, 'right')\n",
    "# p6.add_layout(legend2, 'right')\n",
    "# p1.add_layout(legend, 'right')\n",
    "\n",
    "p10.xaxis.ticker = [0, 1, 2, 3, 4]\n",
    "p10.xaxis.major_label_overrides = {0: 'seconds', 1: 'minutes', 2: 'hours', 3: 'days', 4:'months'}\n",
    "p11.xaxis.ticker = [0, 1, 2, 3, 4]\n",
    "p11.xaxis.major_label_overrides = {0: 'seconds', 1: 'minutes', 2: 'hours', 3: 'days', 4:'months'}\n",
    "\n",
    "show(row([p10, p11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514fe84-de32-411c-beab-c7b7293ff598",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Supplementary\n",
    "\n",
    "stratify: calibration technique, algorithm, Dataset, Testing Subject Characteristics, Study Characteristics, Sensor Data\n",
    "\n",
    "regress: Number of Test Subjects, Power, SBP Distribution STD, DBP Distribution STD, SBP Error STD, DBP Error STD, SBP ED, DBP ED\n",
    "\n",
    "find significant relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1facb8-c512-4799-9d61-18226173255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "supp_df = df_concat.copy()\n",
    "supp_df.columns = [x.replace(' ', '_') for x in supp_df.columns.values]\n",
    "cats = ['Calibration Technique', 'Algorithm', 'Dataset', 'Testing Subject Characteristics', 'Sensor Data']\n",
    "regs = ['Power', 'SBP Distribution STD', 'DBP Distribution STD', 'SBP Error STD', 'DBP Error STD', 'SBP ED', 'DBP ED']\n",
    "cats = [x.replace(' ', '_') for x in cats]\n",
    "regs = [x.replace(' ', '_') for x in regs]\n",
    "\n",
    "corr = supp_df[regs].corr() \n",
    "ax = plt.axes()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n",
    "ax.set_title('Correlation')\n",
    "\n",
    "def regress(reg1, reg2, cats, df):\n",
    "    \n",
    "    if cats == None:\n",
    "        d = df[[reg1, reg2]].dropna()\n",
    "        model = smf.ols(formula=reg1+'~'+reg2, data=d)\n",
    "        results = model.fit()\n",
    "        param = results.params[1]\n",
    "        pval = results.pvalues[1]\n",
    "        ci = results.conf_int().values[1, :]\n",
    "        sig = pval < 0.05\n",
    "    else:\n",
    "        cols = [reg1, reg2]\n",
    "        f = reg1+'~'+reg2\n",
    "        for cat in cats:\n",
    "            cols.append(cat)\n",
    "            f+='+ C('+cat+')'\n",
    "        if len(cats) == 1:\n",
    "            cats = cats[0]\n",
    "        d = df[cols].dropna()\n",
    "        model = smf.ols(formula=f, data=d)\n",
    "        results = model.fit()\n",
    "        param = results.params.values[1:]\n",
    "        pval = results.pvalues.values[1:]\n",
    "        ci = results.conf_int().values[1:, :]\n",
    "        sig = (pval < 0.05).all()\n",
    "    return results, pd.DataFrame([reg1, reg2, cats, param, pval, ci, sig]).T\n",
    "   \n",
    "    \n",
    "\n",
    "df_search = pd.DataFrame()\n",
    "plotted_pairs = []\n",
    "for reg1 in regs:\n",
    "    for reg2 in regs:\n",
    "        if (reg1 != reg2) & ((reg2, reg1) not in plotted_pairs):\n",
    "            plotted_pairs.append((reg1, reg2))\n",
    "            _, res = regress(reg1, reg2, None, supp_df)\n",
    "            df_search = pd.concat([df_search, res])\n",
    "            for cat in cats:\n",
    "                _, res2 = regress(reg1, reg2, [cat], supp_df)\n",
    "                df_search = pd.concat([df_search, res2])\n",
    "df_search.columns = ['Reg1', 'Reg2', 'Cat', 'Slope', 'p-value', 'CI', 'Significant']\n",
    "df_search.reset_index(drop=True, inplace=True)\n",
    "df_search.to_csv('supplementary/regression_results.csv', index=False)\n",
    "df_search[df_search.Significant].to_csv('supplementary/significant_regression_results.csv', index=False)\n",
    "df_search[df_search.Significant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2086e77-9b10-4e4f-b893-16def0b1ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, _ = regress('DBP_ED', 'SBP_ED', ['Testing_Subject_Characteristics'], supp_df)\n",
    "res.summary()\n",
    "# between categories not significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f29739-cadb-4d6e-999b-432caa9a1429",
   "metadata": {},
   "source": [
    "Plots that make sense:\n",
    "\n",
    "1. SBP/DBP Distribution STD vs Power\n",
    "2. SBP Error STD vs DBP Error STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddf5a7-7629-44b2-b721-54b544e52891",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_s, _ = regress('SBP_Distribution_STD', 'Power', None, supp_df)\n",
    "res_d, _ = regress('DBP_Distribution_STD', 'Power', None, supp_df)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))    \n",
    "ax[0].scatter(supp_df['Power'], supp_df['SBP_Distribution_STD'])\n",
    "ax[0].set_xlabel('Power')\n",
    "ax[0].set_ylabel('SBP Distribution STD (mmHg)')\n",
    "plot_x = np.linspace(supp_df['Power'].min(), supp_df['Power'].max(), 100)\n",
    "ax[0].plot(plot_x, res_s.params.values[0] + res_s.params.values[1]*plot_x, linestyle='--', c='r', label='Slope='+\"{:.3f}\".format(res_s.params.values[1])+', CI = ['+\"{:.3f}\".format(res_s.conf_int().values[1:, 0][0])+', '+\"{:.3f}\".format(res_s.conf_int().values[1:, 1][0])+'], p='+\"{:.3e}\".format(res_s.pvalues.values[1]))\n",
    "ax[0].legend()\n",
    "ax[1].scatter(supp_df['Power'], supp_df['DBP_Distribution_STD'])\n",
    "ax[1].set_xlabel('Power')\n",
    "ax[1].set_ylabel('DBP Error STD (mmHg)')\n",
    "ax[1].plot(plot_x, res_d.params.values[0] + res_d.params.values[1]*plot_x, linestyle='--', c='r', label='Slope='+\"{:.3f}\".format(res_d.params.values[1])+', CI = ['+\"{:.3f}\".format(res_d.conf_int().values[1:, 0][0])+', '+\"{:.3f}\".format(res_d.conf_int().values[1:, 1][0])+'], p='+\"{:.3e}\".format(res_d.pvalues.values[1]))\n",
    "ax[1].legend()\n",
    "# res_s.summary(), res_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f423e-163f-4adf-908a-8df183fc85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, _ = regress('SBP_Error_STD', 'DBP_Error_STD', None, supp_df)\n",
    "plt.scatter(supp_df['DBP_Error_STD'], supp_df['SBP_Error_STD'])\n",
    "plot_x = np.linspace(supp_df['DBP_Error_STD'].min(), supp_df['DBP_Error_STD'].max(), 100)\n",
    "plt.plot(plot_x, res.params.values[0] + res.params.values[1]*plot_x, linestyle='--', c='r', label='Slope='+\"{:.3f}\".format(res.params.values[1])+', CI = ['+\"{:.3f}\".format(res.conf_int().values[1:, 0][0])+', '+\"{:.3f}\".format(res.conf_int().values[1:, 1][0])+'], p='+\"{:.3e}\".format(res.pvalues.values[1]))\n",
    "plt.legend()\n",
    "plt.xlabel('DBP Error STD')\n",
    "plt.ylabel('SBP Error STD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619dc10-5881-4eb0-9523-099dbd73086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].scatter(per_concat.log_dt, per_concat['SBP Distribution STD'])\n",
    "ax[1].scatter(per_concat.log_dt, per_concat['DBP Distribution STD'])\n",
    "\n",
    "temp_df = per_concat.copy()\n",
    "temp_df.columns = [x.replace(' ', '_') for x in temp_df.columns]\n",
    "model = smf.ols(formula='SBP_Distribution_STD ~ log_dt', data=temp_df)\n",
    "res_s = model.fit()\n",
    "model = smf.ols(formula='DBP_Distribution_STD ~ log_dt', data=temp_df)\n",
    "res_d = model.fit()\n",
    "\n",
    "plot_xs = np.linspace(temp_df['log_dt'].min(), temp_df['log_dt'].max(), 100)\n",
    "plot_xd = np.linspace(temp_df['log_dt'].min(), temp_df['log_dt'].max(), 100)\n",
    "ax[0].plot(plot_xs, res_s.params.values[0] + res_s.params.values[1]*plot_xs, linestyle='--', c='r', label='Slope='+\"{:.3f}\".format(res_s.params.values[1])+', CI = ['+\"{:.3f}\".format(res_s.conf_int().values[1:, 0][0])+', '+\"{:.3f}\".format(res_s.conf_int().values[1:, 1][0])+'], p='+\"{:.3e}\".format(res_s.pvalues.values[1]))\n",
    "ax[1].plot(plot_xs, res_d.params.values[0] + res_d.params.values[1]*plot_xd, linestyle='--', c='r', label='Slope='+\"{:.3f}\".format(res_d.params.values[1])+', CI = ['+\"{:.3f}\".format(res_d.conf_int().values[1:, 0][0])+', '+\"{:.3f}\".format(res_d.conf_int().values[1:, 1][0])+'], p='+\"{:.3e}\".format(res_d.pvalues.values[1]))\n",
    "ax[0].legend()\n",
    "ax[0].set_xticks([0,1,2,3,4])\n",
    "ax[0].set_ylabel('∆SBP Distribution STD')\n",
    "ax[0].set_xticklabels(['seconds','minutes','hours','days','months'])\n",
    "ax[0].set_xlabel('Time between calibration and test')\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('∆DBP Distribution STD')\n",
    "ax[1].set_xlabel('Time between calibration and test')\n",
    "ax[1].set_ylabel('∆SBP Distribution STD')\n",
    "ax[1].set_xticklabels(['seconds','minutes','hours','days','months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31562e-8222-4bb9-9ec0-4931322dd286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in df_search.index:\n",
    "    dsearch = df_search.iloc[i]\n",
    "    figname = 'supplementary/other_figs/' + dsearch.Reg2+'_'+dsearch.Reg1\n",
    "    f = dsearch.Reg1+'~'+dsearch.Reg2\n",
    "    if dsearch.Cat == None:\n",
    "        plot_df = supp_df[[dsearch.Reg1, dsearch.Reg2]]\n",
    "        sns.lmplot(data=plot_df, x=dsearch.Reg2, y=dsearch.Reg1, height=5)\n",
    "    else:\n",
    "        plot_df = supp_df[[dsearch.Reg1, dsearch.Reg2, dsearch.Cat]]\n",
    "        f+='C('+dsearch.Cat+')'\n",
    "        sns.lmplot(data=plot_df, x=dsearch.Reg2, y=dsearch.Reg1, hue=dsearch.Cat, height=5)\n",
    "        figname+='_'+dsearch.Cat\n",
    "    ax = plt.gca()\n",
    "    plt.savefig(figname+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a04792-22d4-40e4-96e1-053c43d462d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d255f34-51f3-4164-8ade-a7e10788e485",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Benchmark Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc7502-48e7-41bc-a223-57ecd7eb7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = pd.read_excel('../metadata.xlsx', sheet_name='Benchmarks')\n",
    "benchmark_key = pd.read_excel('../metadata.xlsx', sheet_name='Benchmark Key')\n",
    "benchmark_data['ED'] = benchmark_data['SBP ED'].astype(str) + '/' + benchmark_data['DBP ED'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173fe0e-2c13-48a5-9568-4568033981f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_name(d, key):\n",
    "    if d == d:\n",
    "        row = key[key['Benchmark Item Name'] == d]\n",
    "        return row['Display Name'].values[0]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "cols = ['Filter', 'Estimator']\n",
    "for col in cols:\n",
    "    benchmark_data[col] = benchmark_data[col].apply(assign_name, args=(benchmark_key, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52472299-dc39-4a60-a254-174c48b8bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import Category10_3\n",
    "from bokeh.models import Legend, LegendItem\n",
    "\n",
    "output_file('./_includes/replicated_ed_scatter.html')\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 10px\"> Dataset: @{Dataset} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Filter: @{Filter} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Estimator: @{Estimator} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Reported SBP/DBP ED: @{Reported SBP ED} / @{Reported DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Replicated SBP/DBP ED: @{SBP ED} / @{DBP ED}</span> <br>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "p21 = figure(title = \"Reported vs Replicated ED for SBP and DBP\", background_fill_color=\"#fafafa\", plot_width=400, plot_height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p21.xaxis.axis_label = 'Reported SBP ED'\n",
    "p21.yaxis.axis_label = 'Replicated SBP ED'\n",
    "p22 = figure(title = \"\", background_fill_color=\"#fafafa\", plot_width=485, plot_height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p22.xaxis.axis_label = 'Reported DBP ED'\n",
    "p22.yaxis.axis_label = 'Replicated DBP ED'\n",
    "\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']\n",
    "shapes = ['circle', 'triangle', 'diamond', 'plus']\n",
    "dset_unique = benchmark_data['Dataset'].unique()\n",
    "filter_unique = benchmark_data['Filter'].unique()\n",
    "color_dict = {}\n",
    "for i in range(len(dset_unique)):\n",
    "    color_dict[dset_unique[i]] = cs[i]\n",
    "shape_dict = {}\n",
    "for i in range(len(filter_unique)):\n",
    "    shape_dict[filter_unique[i]] = shapes[i]\n",
    "benchmark_data['color'] = benchmark_data['Dataset'].apply(lambda x: color_dict[x])\n",
    "benchmark_data['shape'] = benchmark_data['Filter'].apply(lambda x: shape_dict[x])\n",
    "\n",
    "legend_it = []\n",
    "for i in range(len(dset_unique)):\n",
    "    d = benchmark_data[benchmark_data['Dataset'] == dset_unique[i]]\n",
    "    c1 = p21.scatter('Reported SBP ED', 'SBP ED', source=ColumnDataSource(d), size=12, color='color', marker='shape')\n",
    "    c2 = p22.scatter('Reported DBP ED', 'DBP ED', source=ColumnDataSource(d), size=12, color='color', marker='shape')\n",
    "\n",
    "    legend_it.append((dset_unique[i], [c1, c2]))\n",
    "legend = Legend(items=legend_it)\n",
    "legend.click_policy='hide'\n",
    "p22.add_layout(legend, 'right')\n",
    "p22.legend.title = 'Dataset'\n",
    "\n",
    "show(row([p21, p22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04c2b5-b987-48eb-a4c1-10e2b7564987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.transform import factor_cmap, factor_mark\n",
    "from bokeh.palettes import Category10_3\n",
    "from bokeh.models import Legend, LegendItem\n",
    "\n",
    "output_file('./_includes/replicated_ed_diff_scatter.html')\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "        <div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 10px\"> Dataset: @{Dataset} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Filter: @{Filter} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Estimator: @{Estimator} </span> <br>\n",
    "                <span style=\"font-size: 10px\"> Reported SBP/DBP ED: @{Reported SBP ED} / @{Reported DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> Replicated SBP/DBP ED: @{SBP ED} / @{DBP ED}</span> <br>\n",
    "                <span style=\"font-size: 10px\"> SBP/DBP ED Difference: @{SBP ED Difference} / @{DBP ED Difference} </span> <br>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "p1 = figure(title = \"Replicated-Reported ED Difference for SBP and DBP\", background_fill_color=\"#fafafa\", plot_width=550, plot_height=400, toolbar_location='above', tools=[hover, 'pan', 'wheel_zoom' ,'box_zoom', 'reset'])\n",
    "p1.xaxis.axis_label = 'Replicated DBP ED - Reported DBP ED'\n",
    "p1.yaxis.axis_label = 'Replicated SBP ED - Reported SBP ED'\n",
    "\n",
    "cs = ['#a6cee3', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a', '#ffff99', '#b15928', '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f']\n",
    "shapes = ['circle', 'triangle', 'diamond', 'plus']\n",
    "dset_unique = benchmark_data['Dataset'].unique()\n",
    "filter_unique = benchmark_data['Filter'].unique()\n",
    "color_dict = {}\n",
    "for i in range(len(dset_unique)):\n",
    "    color_dict[dset_unique[i]] = cs[i]\n",
    "shape_dict = {}\n",
    "for i in range(len(filter_unique)):\n",
    "    shape_dict[filter_unique[i]] = shapes[i]\n",
    "benchmark_data['color'] = benchmark_data['Dataset'].apply(lambda x: color_dict[x])\n",
    "benchmark_data['shape'] = benchmark_data['Filter'].apply(lambda x: shape_dict[x])\n",
    "benchmark_data['SBP ED Difference'] = benchmark_data['SBP ED'].astype(float) - benchmark_data['Reported SBP ED'].astype(float)\n",
    "benchmark_data['DBP ED Difference'] = benchmark_data['DBP ED'].astype(float) - benchmark_data['Reported DBP ED'].astype(float)\n",
    "\n",
    "legend_it = []\n",
    "for i in range(len(dset_unique)):\n",
    "    d = benchmark_data[benchmark_data['Dataset'] == dset_unique[i]]\n",
    "    c1 = p1.scatter('DBP ED Difference', 'SBP ED Difference', source=ColumnDataSource(d), size=12, color='color', marker='shape')\n",
    "    legend_it.append((dset_unique[i], [c1]))\n",
    "legend = Legend(items=legend_it)\n",
    "legend.click_policy='hide'\n",
    "p1.add_layout(legend, 'right')\n",
    "p1.legend.title = 'Dataset'\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dd9c2-dd0d-4219-91ae-9e06bd842995",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = benchmark_data.copy().dropna(how='all')\n",
    "def assign_url(d, key):\n",
    "    if d == d:\n",
    "        row = key[key['Display Name'] == d]\n",
    "        return '<a href=\"' + row['URL'].values[0] + '\">' + row['Display Name'].values[0] + '</a>'\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "cols = ['Filter', 'Estimator']\n",
    "for col in cols:\n",
    "    d[col] = d[col].apply(assign_url, args=(benchmark_key, ))\n",
    "\n",
    "d = d.pivot(index=['Dataset', 'Filter'], columns='Estimator', values='ED').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848fea8-a81d-4576-a9a5-039b3e9469ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index().to_html('./_includes/benchmark_table.html', index=False, render_links=True, table_id='btable', escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492df5e0-d791-4acf-8cdd-fcec7411f723",
   "metadata": {},
   "source": [
    "# Create Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87273f51-b6d2-4044-9caf-7bc63db311a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../metadata.xlsx', sheet_name='Publicly Available Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fff67-c3a3-4342-b628-1e9d02d212e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Dataset Name'] = make_clickable(data['Dataset Name'], data['Dataset URL'])\n",
    "data['Article URL'] = make_clickable('Article URL', data['Dataset URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98864588-f27d-4f3a-ba7f-8baa57ef96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Dataset Name', 'Article URL', 'Sensor Data', 'Number of Subjects', 'Study Characteristics', 'BP Distribution SBP', 'BP Distribution DBP', 'Access', 'Notes']].to_html('./_includes/dataset_table.html', index=False, render_links=True, table_id='dtable', escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2d371-3bdb-45eb-bcbd-1c4bdd27f7cc",
   "metadata": {},
   "source": [
    "# Remove Doctype formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756ac93-6fbb-457b-9332-6c4c6b6ab369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for fname in os.listdir('./_includes'):\n",
    "    if ('scatter' in fname) | ('_stats' in fname):\n",
    "        fpath = './_includes/' + fname\n",
    "        with open(fpath, 'rb') as fin:\n",
    "            data = fin.read().splitlines(True)\n",
    "        with open(fpath, 'wb') as fout:\n",
    "            fout.writelines(data[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
