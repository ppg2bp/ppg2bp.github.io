---
layout: page
title: Methods
permalink: /methods/
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<h2> Method </h2>

To improve transparency of our analysis, we provide detailed information about the systematic review process.

<h4> Protocol and Registration, Information Sources, and Search </h4>
Keywords "wearable", "blood pressure", "monitoring", "estimation", "systolic", "diastolic", and "cuffless" were entered into the search tool [Publish or Perish](https://harzing.com/resources/publish-or-perish) on 5/10/2022 which retrieves and analyzes academic citations from external data sources, including Crossref, Google Scholar, PubMed, Scopus, and Semantic Scholar. The Maximum number of results were specified as 1000 and the articles were specified in the time-frame of 1979-2022. Additional studies were included from Google Scholar alerts of "blood pressure device" and from article references.

<h4> Eligibility Criteria </h4>
We develop an Eligibility Criteria to determine whether studies should be included or excluded from analysis. First, we include studies that report mean absolute error (MAE) or bias±standard deviation of error (ME) for Systolic and Diastolic Blood Pressure estimation. The AAMI/ANSI/ISO, BHS, and IEEE Standards all require either ME or MAE. Moreover, we can compute ME to MAE and vice versa (assuming zero bias) through a folded normal distribution. Second, we require the article to be written in the English language. Third, we only include studies that do not suffer from data leakage. In order to properly compare and contrast data, we must stratify by algorithmic level calibration technique. We coin the terms "record level split without personalization", "subject level split", and "personalization" to distinguish between calibration techniques. Record level split without personalization involves having data in the training and testing set from the same subjects, therefore suffering from data leakage. For example, randomly sampled segments from a subject are included in both the training and test set. Unfortunately there are currently no useful applications for the record level split without personalization calibration technique. On the other hand, Subject level split, which can be thought of as "population level calibration", involves using different subjects in the training and testing sets. For example, if 100 subjects are in the dataset, 50 subjects are used for training the model and the other 50 are used for testing the model. In contrast, personalization, which can be thought of as "individual level calibration", is a subset of record level split. This involves performing record level split with a temporal constraint, in which the training data is selected as the first portion of records and the testing data is selected as the latter portion of the record without overlap with the training data. For example, if a record for a single subject is 1 month long, data from the first day is used for training and the rest is used for testing. This individual level model is usually recalibrated at arbitrary intervals due to physiological changes that may render the model inaccurate. We only include articles that claim to perform subject level split or personalization. Fourth, we exclude models that dynamically update based on individual subjects and their time stamps. Fifth, we only include studies that perform experiments on human subjects, as we aim to deploy these devices on humans. Finally, we only include studies that have number of test subjects greater than 1 due to inability to compute blood pressure distributions of subject population. For studies that are not included, we provide a exclusion reason.

<h4> Data Collection Process and Data Items </h4>

A single author performed extraction of predefined data parameters. For studies that had multiple protocols and reported multiple results, the multiple entries were made in the compiled database. The predefined data fields include: Key Devices and Measurements, Calibration Technique, Algorithm,	Dataset, Number of Test Subjects, Training Subject Characteristics, Testing Subject Characteristics, Study Characteristics (observational or interventional study), BP Distribution, Evaluation Metric, and Reported Result. For personalization articles, we report the Time between Calibration and Test. To estimate the SBP and DBP population standard deviation when the BP distribution was not provided in the code, we used (if available) figures that had an axis with Reference SBP or DBP values, specifically correlation plots (Reference vs Estimated) and error plots (Reference vs Error). On the other hand, a Bland-Altman plot is not appropriate because the x-axis is the Average of the reference and estimated. Using these figures, we isolated the red, green or blue channels depending on the colors of the points of interest. Then, we sum the values along the non-reference axis, normalized them to attain a probability distribution function, fit a gaussian curve, and take the mean and standard deviation. The mean and standard deviation were reported as the BP distribution statistic. The implementation can be found at ____. Finally, for studies that were included in our meta-analysis, we report the implementation availability and the dataset availability. For a description of parameters and their values, refer to <a href="{{site.baseurl}}/key/">Key</a>. Note: Because one author summarized all studies, there could have been bias in extracting the results.

<h4> Summary Statistics </h4>

We adopt an estimate to evaluate estimation accuracy for studies that perform subject level split, coined Explained Deviation ($$ED$$), used to compute the effectiveness of a device with estimation error parameterized by ($$\mu_\epsilon, \sigma_\epsilon$$) on a population parameterized by ($$\mu_{pop}, \sigma_{pop}$$), where $$\mu$$ represents the mean and $$\sigma$$ represents the standard deviation. The ED can be computed as $$ ED = \frac{\sigma_{pop}}{\sigma_\epsilon}$$. The higher the ED, the better the device performs. On the other hand, an ED of 1 indicates that the estimator performs no better than an estimator that predicts a constant value. This is equivalent to an F-test for ratio of two variances with equal sample size, the null hypothesis $$H_0: ED \leq ED_{min}$$, and the alternative hypothesis $$H_1: ED \gt ED_{min}$$ where $$ED_{min}$$ is the computed minimum Explained Deviation that meets the standards. Furthermore, confidence intervals can be computed using the F-distribution by determining the probability $$P(\sqrt{F_{\alpha/2}(n-1, n-1)} ED_{est} < ED_{true} < \sqrt{F_{1-\alpha/2}(n-1, n-1)} ED_{est})  = 1-\alpha $$ where $$\alpha$$ is the level of significance, $$P$$ is the probability, $$F$$ is the F-distribution, and $$n$$ in the sample size. 

Using the same formulation, we compute $$ED$$ for personalization. However, in this case, we must take the change in BP of each subject into account: $$ED = \frac{\sigma_{\Delta BP, err}}{\sigma_{\Delta BP}}$$, where $$\sigma_{\Delta BP, err}$$ is the change in BP prediction error of the study cohort and $$\sigma_{\Delta BP}$$ is the standard deviation of the BP changes of the study cohort.

Moreover, we compute power ($$p$$) to determine whether the sample size is sufficient to detect the reported result. To do this we need to define selected level of significance, $$\alpha$$, and $$\beta=1-p$$. The ANSI/AAMI/ISO 81060-2 requires device error to have an absolute mean and standard deviation within 5±8mmHg with $$\alpha=0.05$$ and $$\beta=0.02$$, corresponding to $$p=0.98$$ and a sample size of 83. To compute this, they consider a two independent sample and continuous outcome study. The minimum sample size for a given $$\alpha$$ and $$\beta$$ is: $$n=2(\frac{z_{1-\alpha/2}+z_{1-\beta}}{ES})^2$$ where $$ES$$ is the effect size, $$z_{1-\alpha/2}$$ is the z-score at $$1-\alpha/2$$. Assuming $$ES=\frac{5}{8}$$, the minimum number of subjects for $$\alpha=0.05$$ and $$p=1-\beta=0.98$$ is 83. Conversely, the power of a study can be computed as $$p=1-\beta=\phi(ES \sqrt{\frac{n}{2}}-z_{1-\alpha/2}))$$ where $$ES$$ (effect size) is given by error bias/error standard deviation $$ES=\frac{5}{8}$$, and $$\phi$$ is the cumulative distribution function of a normal distribution. In this case, the null hypothesis ($$H_0$$) is that the device has a mean difference and standard deviation of error above 5mmHg and 8mmHg. If the power is 0.98, that means that the probability of rejecting the $$H_0$$ given the alternative hypothesis is true is greater than 98%.
